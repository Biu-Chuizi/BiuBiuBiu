{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ab5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python dcgan_mnist.py --output output\n",
    "# import the necessary packages\n",
    "from pyimagesearch.dcgan import Generator\n",
    "from pyimagesearch.dcgan import Discriminator\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "from sklearn.utils import shuffle\n",
    "from imutils import build_montages\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCELoss\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "# custom weights initialization called on generator and discriminator\n",
    "def weights_init(model):\n",
    "    # get the class name\n",
    "    classname = model.__class__.__name__\n",
    "    # check if the classname contains the word \"conv\"\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        # intialize the weights from normal distribution\n",
    "        nn.init.normal_(model.weight.data, 0.0, 0.02)\n",
    "    # otherwise, check if the name contains the word \"BatcnNorm\"\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        # intialize the weights from normal distribution and set the\n",
    "        # bias to 0\n",
    "        nn.init.normal_(model.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(model.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c353ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "    help=\"path to output directory\")\n",
    "ap.add_argument(\"-e\", \"--epochs\", type=int, default=20,\n",
    "    help=\"# epochs to train for\")\n",
    "ap.add_argument(\"-b\", \"--batch-size\", type=int, default=128,\n",
    "    help=\"batch size for training\")\n",
    "args = vars(ap.parse_args())\n",
    "# store the epochs and batch size in convenience variables\n",
    "NUM_EPOCHS = args[\"epochs\"]\n",
    "BATCH_SIZE = args[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device we will be using\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# define data transforms\n",
    "dataTransforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "# load the MNIST dataset and stack the training and testing data\n",
    "# points so we have additional training data\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "trainData = MNIST(root=\"data\", train=True, download=True,\n",
    "            transform=dataTransforms)\n",
    "testData = MNIST(root=\"data\", train=False, download=True,\n",
    "            transform=dataTransforms)\n",
    "data = torch.utils.data.ConcatDataset((trainData, testData))\n",
    "# initialize our dataloader\n",
    "dataloader = DataLoader(data, shuffle=True,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate steps per epoch\n",
    "stepsPerEpoch = len(dataloader.dataset) // BATCH_SIZE\n",
    "# build the generator, initialize it's weights, and flash it to the\n",
    "# current device\n",
    "print(\"[INFO] building generator...\")\n",
    "gen = Generator(inputDim=100, outputDim=512, outputChannels=1)\n",
    "gen.apply(weights_init)\n",
    "gen.to(DEVICE)\n",
    "# build the discriminator, initialize it's weights, and flash it to\n",
    "# the current device\n",
    "print(\"[INFO] building discriminator...\")\n",
    "disc = Discriminator(depth=1)\n",
    "disc.apply(weights_init)\n",
    "disc.to(DEVICE)\n",
    "# initialize optimizer for both geneator and discriminator\n",
    "genOpt = Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
    "            weight_decay=0.0002 / NUM_EPOCHS)\n",
    "discOpt = Adam(disc.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
    "            weight_decay=0.0002 / NUM_EPOCHS)\n",
    "# initialize BCELoss function\n",
    "criterion = BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f65169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generate some benchmark noise so we can consistently\n",
    "# visualize how the generative modeling is learning\n",
    "print(\"[INFO] starting training...\")\n",
    "benchmarkNoise = torch.randn(256, 100, 1, 1, device=DEVICE)\n",
    "# define real and fake label values\n",
    "realLabel = 1\n",
    "fakeLabel = 0\n",
    "# loop over the epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # show epoch information and compute the number of batches per\n",
    "    # epoch\n",
    "    print(\"[INFO] starting epoch {} of {}...\".format(epoch + 1,\n",
    "        NUM_EPOCHS))\n",
    "    # initialize current epoch loss for generator and discriminator\n",
    "    epochLossG = 0\n",
    "    epochLossD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d55a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x in dataloader:\n",
    "        # zero out the discriminator gradients\n",
    "        disc.zero_grad()\n",
    "        # grab the images and send them to the device\n",
    "        images = x[0]\n",
    "        images = images.to(DEVICE)\n",
    "        # get the batch size and create a labels tensor\n",
    "        bs =  images.size(0)\n",
    "        labels = torch.full((bs,), realLabel, dtype=torch.float,\n",
    "                device=DEVICE)\n",
    "        # forward pass through discriminator\n",
    "        output = disc(images).view(-1)\n",
    "        # calculate the loss on all-real batch\n",
    "        errorReal = criterion(output, labels)\n",
    "        # calculate gradients by performing a backward pass\n",
    "        errorReal.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b56862",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # set all generator gradients to zero\n",
    "        gen.zero_grad()\n",
    "        # update the labels as fake labels are real for the generator\n",
    "        # and perform a forward pass  of fake data batch through the\n",
    "        # discriminator\n",
    "        labels.fill_(realLabel)\n",
    "        output = disc(fake).view(-1)\n",
    "        # calculate generator's loss based on output from\n",
    "        # discriminator and calculate gradients for generator\n",
    "        errorG = criterion(output, labels)\n",
    "        errorG.backward()\n",
    "        # update the generator\n",
    "        genOpt.step()\n",
    "        # add the current iteration loss of discriminator and\n",
    "        # generator\n",
    "        epochLossD += errorD\n",
    "        epochLossG += errorG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # display training information to disk\n",
    "    print(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(\n",
    "            epochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
    "    # check to see if we should visualize the output of the\n",
    "    # generator model on our benchmark data\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        # set the generator in evaluation phase, make predictions on\n",
    "        # the benchmark noise, scale it back to the range [0, 255],\n",
    "        # and generate the montage\n",
    "        gen.eval()\n",
    "        images = gen(benchmarkNoise)\n",
    "        images = images.detach().cpu().numpy().transpose((0, 2, 3, 1))\n",
    "        images = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
    "        images = np.repeat(images, 3, axis=-1)\n",
    "        vis = build_montages(images, (28, 28), (16, 16))[0]\n",
    "        # build the output path and write the visualization to disk\n",
    "        p = os.path.join(args[\"output\"], \"epoch_{}.png\".format(\n",
    "            str(epoch + 1).zfill(4)))\n",
    "        cv2.imwrite(p, vis)\n",
    "        # set the generator to training mode\n",
    "        gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f51acc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
