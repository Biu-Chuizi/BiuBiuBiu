{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python fine_tune.py\n",
    "# import the necessary packages\n",
    "from pyimagesearch import config\n",
    "from pyimagesearch import create_dataloaders\n",
    "from imutils import paths\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5317b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define augmentation pipelines\n",
    "trainTansform = transforms.Compose([\n",
    "\ttransforms.RandomResizedCrop(config.IMAGE_SIZE),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.RandomRotation(90),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=config.MEAN, std=config.STD)\n",
    "])\n",
    "valTransform = transforms.Compose([\n",
    "\ttransforms.Resize((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=config.MEAN, std=config.STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders\n",
    "(trainDS, trainLoader) = create_dataloaders.get_dataloader(config.TRAIN,\n",
    "\ttransforms=trainTansform, batchSize=config.FINETUNE_BATCH_SIZE)\n",
    "(valDS, valLoader) = create_dataloaders.get_dataloader(config.VAL,\n",
    "\ttransforms=valTransform, batchSize=config.FINETUNE_BATCH_SIZE,\n",
    "\tshuffle=False)\n",
    "The real change comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the ResNet50 model\n",
    "model = resnet50(pretrained=True)\n",
    "numFeatures = model.fc.in_features\n",
    "# loop over the modules of the model and set the parameters of\n",
    "# batch normalization modules as not trainable\n",
    "for module, param in zip(model.modules(), model.parameters()):\n",
    "\tif isinstance(module, nn.BatchNorm2d):\n",
    "\t\tparam.requires_grad = False\n",
    "# define the network head and attach it to the model\n",
    "headModel = nn.Sequential(\n",
    "\tnn.Linear(numFeatures, 512),\n",
    "\tnn.ReLU(),\n",
    "\tnn.Dropout(0.25),\n",
    "\tnn.Linear(512, 256),\n",
    "\tnn.ReLU(),\n",
    "\tnn.Dropout(0.5),\n",
    "\tnn.Linear(256, len(trainDS.classes))\n",
    ")\n",
    "model.fc = headModel\n",
    "# append a new classification top to our feature extractor and pop it\n",
    "# on to the current device\n",
    "model = model.to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize loss function and optimizer (notice that we are only\n",
    "# providing the parameters of the classification top to our optimizer)\n",
    "lossFunc = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDS) // config.FINETUNE_BATCH_SIZE\n",
    "valSteps = len(valDS) // config.FINETUNE_BATCH_SIZE\n",
    "# initialize a dictionary to store training history\n",
    "H = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [],\n",
    "\t\"val_acc\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over epochs\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "for e in tqdm(range(config.EPOCHS)):\n",
    "\t# set the model in training mode\n",
    "\tmodel.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\t# initialize the number of correct predictions in the training\n",
    "\t# and validation step\n",
    "\ttrainCorrect = 0\n",
    "\tvalCorrect = 0\n",
    "\t# loop over the training set\n",
    "\tfor (i, (x, y)) in enumerate(trainLoader):\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = model(x)\n",
    "\t\tloss = lossFunc(pred, y)\n",
    "\t\t# calculate the gradients\n",
    "\t\tloss.backward()\n",
    "\t\t# check if we are updating the model parameters and if so\n",
    "\t\t# update them, and zero out the previously accumulated gradients\n",
    "\t\tif (i + 2) % 2 == 0:\n",
    "\t\t\topt.step()\n",
    "\t\t\topt.zero_grad()\n",
    "\t\t# add the loss to the total training loss so far and\n",
    "\t\t# calculate the number of correct predictions\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\ttrainCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\ttorch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch off autograd\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in valLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = model(x)\n",
    "\t\t\ttotalValLoss += lossFunc(pred, y)\n",
    "\t\t\t# calculate the number of correct predictions\n",
    "\t\t\tvalCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\t\ttorch.float).sum().item()\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgValLoss = totalValLoss / valSteps\n",
    "\t# calculate the training and validation accuracy\n",
    "\ttrainCorrect = trainCorrect / len(trainDS)\n",
    "\tvalCorrect = valCorrect / len(valDS)\n",
    "\t# update our training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"train_acc\"].append(trainCorrect)\n",
    "\tH[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "\tH[\"val_acc\"].append(valCorrect)\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, config.EPOCHS))\n",
    "\tprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "\t\tavgTrainLoss, trainCorrect))\n",
    "\tprint(\"Val loss: {:.6f}, Val accuracy: {:.4f}\".format(\n",
    "\t\tavgValLoss, valCorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cebb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the total time needed to perform the training\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(config.FINETUNE_PLOT)\n",
    "# serialize the model to disk\n",
    "torch.save(model, config.FINETUNE_MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
