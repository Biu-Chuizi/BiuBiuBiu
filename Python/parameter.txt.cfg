# # # 训练需要修改class,网络参数暂时还不清楚，angle是否有必要需要验证
# # # filters = 3 x (classes数目+5)/////(classes + coords + 1)*<number of mask>
# # # 如果显存很小，将random设置为0，关闭多尺度训练；
# # # 【region】层上方第一个【convolution】层，其中的filters值要进行修改，改成(classes+ coords+ 1)* (NUM) ，我的情况中：(1+4+1)* 5=30，我把filters 的值改成了30 //num=9 在yolov3中
[net]
# # # Testing
batch=1
subdivisions=1
# # # Training
batch=64
                                # # 每一次迭代送到网络的图片数量，也叫批数量。增大这个可以让网络在较少的迭代次数内完成一个epoch。在固定最大迭代次数的前提下，增加batch会延长训练时间，
                                # # 但会更好的寻找到梯度下降的方向。如果你显存够大，可以适当增大这个值来提高内存利用率。这个值是需要大家不断尝试选取的，过小的话会让训练不够收敛，过大会陷入局部最优。
                                # # 在显存允许的情况下，可适当增加batch大小，可以一定程度上减少NAN的出现，注意out of memory 和 resizing 的问题
subdivisions=16                  ### 16， subdivisions=1时占用GPU memory 15.6G左右
                                # # 它会让你的每一个batch不是一下子都丢到网络里。而是分成subdivision对应数字的份数，一份一份的跑完后，
                                # # 在一起打包算作完成一次iteration。这样会降低对显存的占用情况。如果设置这个参数为1的话就是一次性把所有batch的图片都丢到网络里，如果为2的话就是一次丢一半。
width=480/320
height=480/320
# # # 图片尺寸满足32的倍数，可以不相等，尺寸越大对小目标的识别效果约好，在DarkNet网络中，执行5次步长为2卷积（32=2^5），降采样，其卷积操作如下：
# # # x = DarknetConv2D_BN_Leaky(num_filters, (3, 3), strides=(2, 2))(x)
# # # 在最底层时，特征图尺寸需要满足为奇数，如13，以保证中心点落在唯一框中。如果为偶数时，则中心点落在中心的4个框中，导致歧义。
channels=3
momentum=0.9
### 动量参数，影响梯度下降到最优值的速度
decay=0.0005
### 权重衰减正则项，防止过拟合
angle=0
### 图片旋转角度来生成更多训练样本，这个用来增强训练效果的。从本质上来说，就是通过旋转图片来变相的增加训练样本集。
saturation = 1.5
### 饱和度调整来生成更多训练样本,为了增强训练效果
exposure = 1.5
### 曝光度调整来生成更多训练样本,为了增强训练效果
hue=.1
### 色调调整来生成更多训练样本,为了增强训练效果

learning_rate = 0.0005
# 初始学习率,刚开始训练时可以将学习率设置的高一点，刚开始训练时：学习率以 0.01 ~ 0.001 为宜。一定轮数过后：逐渐减缓。
# 接近训练结束：学习速率的衰减应该在100倍以上。训练发散的话可以降低学习率。
# 学习遇到瓶颈，loss不变的话也减低学习率,learning_rate * GPUs = 0.001
burn_in = 2000
#1000             ### 学习率控制参数,1000*gpu数量
max_batches = 20000
#20000       ### 最大迭代次数,需要配合steps 和 scales 使用，1000*gpu数量, 可以用classes*2000*gup数量来计算迭代次数
policy=steps
### 学习率策略,一般都是step这种步进式，有如下policy：CONSTANT, STEP, EXP, POLY, STEPS, SIG, RANDOM
steps=10000,15000
### 学习率变动步长
scales=.1,.1
### 学习率变动因子
                                # # step，scales：这两个是组合一起的，举个例子：learn_rate: 0.001, step:100,25000,35000 
                                # # scales: 10, .1, .1 这组数据的意思就是在0-100次iteration期间learning rate为原始0.001，在100-25000次iteration期间learning rate为原始的10倍0.01，
                                # # 在25000-35000次iteration期间learning rate为当前值的0.1倍，就是0.001， 在35000到最大iteration期间使用learning rate为当前值的0.1倍，就是0.0001。
                                # # 随着iteration增加，降低学习率可以是模型更有效的学习，也就是更好的降低train loss


[convolutional]
batch_normalize=1
### 是否做BN
filters=32
### 卷积核数目，输出多少个特征图
size=3
### 卷积核尺寸
stride=1
### 做卷积运算的步长
pad=1
### 如果pad为0,padding由 padding参数指定。如果pad为1，padding大小为size/2
activation=leaky
### 激活函数：logistic，loggy，relu，elu，relie，plse，hardtan，lhtan，linear，ramp，leaky，tanh，stair

# Downsample

[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear
# shortcut部分是卷积的跨层连接，就像Resnet中使用的一样，参数from是$-3$，意思是shortcut的输出是通过与先前的倒数第三层网络相加而得到。

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# 卷积核尺寸3*3配合padding且步长为1时，不改变feature map的大小
[shortcut]
from=-3
activation=linear

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=leaky
# 卷积核尺寸为3*3，配合padding且步长为2时，feature map变为原来的一半大小
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky

[shortcut]
from=-3
activation=linear

######################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
### region前最后一个卷积层的filters数是特定的，计算公式为filter=num(3)*(classes+5),5的意义是5个坐标，论文中的tx,ty,tw,th,to
activation=linear

[yolo]
mask = 6,7,8    
### 每个yolo（检测）层获得与其大小相关联的3个锚点，掩码选择锚索引。此处选择最后三个锚点。YOLO预测（（52×52）+（26×26）+ 13×13））×3 = 10647个边界框，
### 如果选择的三个锚点偏大，会生成大量预测框，可能拖累速度？
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326       
### 预选框，可以手工挑选,也可以通过k means 从训练样本中学出
classes=1###2
num=9
### 应该是与上面的anchors对应
jitter=.3
#                              ★ 数据增强手段，此处jitter为随机调整宽高比的范围
ignore_thresh = .5
truth_thresh = 1
#                              ★ 参与计算的IOU阈值大小.当预测的检测框与ground true的IOU大于ignore_thresh的时候，参与
#                              loss的计算，否则，检测框的不参与损失计算。
#                              ★ 理解：目的是控制参与loss计算的检测框的规模，当ignore_thresh过于大，接近于1的时候，那么参与
#                              检测框回归loss的个数就会比较少，同时也容易造成过拟合；而如果ignore_thresh设置的过于小，那么
#                              参与计算的会数量规模就会很大。同时也容易在进行检测框回归的时候造成欠拟合。
#                              ★ 参数设置：一般选取0.5-0.7之间的一个值

random=1        
###1
#                              ★ 为1打开随机多尺度训练，为0则关闭
#                              ★★ 当打开随机多尺度训练时，前面设置的网络输入尺寸width和height其实就不起作用了，width
#                              会在320到608之间随机取值，且width=height，没10轮随机改变一次，一般建议可以根据自己需要修改
#                              随机尺度训练的范围，这样可以增大batch

[route]
layers = -4
# 它具有可以具有一个或两个值的属性层。
# 当属性只有一个值时，它会输出由该值索引的网络层的特征图。 在我们的示例中，它是-4，因此这个层将从Route层向后输出第4层的特征图。

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 61

# 当图层有两个值时，它会返回由其值所索引的图层的连接特征图。 在我们的例子中，它是-1,61，并且该图层将输出来自上一层（-1）和第61层的特征图，并沿深度的维度连接。

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
# # # region前最后一个卷积层的filters数是特定的，计算公式为filter=num(3)*(classes+5),5的意义是5个坐标，论文中的tx,ty,tw,th,to
activation=linear

[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
# # # 3个尺度（scale）的特征图，每个特征图3个anchor框，共9个框，从小到大排列；
# # # 框1~3在大尺度（52x52）特征图中使用，框4~6是中尺度（26x26），框7~9是小尺度（13x13）；
# # # 大尺度特征图用于检测小物体，小尺度检测大物体；
# # # 9个anchor来源于边界框（Bounding Box）的K-Means聚类。
classes=1###2
num=9
jitter=.3
ignore_thresh = .5
truth_thresh = 1
random=1
###1

[route]
layers = -4

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = -1, 36



[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=18
# # # region前最后一个卷积层的filters数是特定的，计算公式为filter=num(3)*(classes+5),5的意义是5个坐标，论文中的tx,ty,tw,th,to
activation=linear

[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=1
num=9
jitter=.3
ignore_thresh = .5
                            # 参与计算的IOU阈值大小.当预测的检测框与ground true的IOU大于ignore_thresh的时候，参与loss的计算，否则，检测框的不参与损失计算。
                            # 参数目的和理解：目的是控制参与loss计算的检测框的规模，当ignore_thresh过于大，接近于1的时候，那么参与检测框回归loss的个数就会
                            # 比较少，同时也容易造成过拟合；而如果ignore_thresh设置的过于小，那么参与计算的会数量规模就会很大。同时也容易在进行检测框回归的时候造成欠拟合。
                            # 参数设置：一般选取0.5-0.7之间的一个值，之前的计算基础都是小尺度（13*13）用的是0.7，（26*26）用的是0.5。这次先将0.5更改为0.7。
                            # 参考：https://www.e-learn.cn/content/qita/804953
truth_thresh = 1
random=1
                            # # # 最后一行的random，是一个开关。如果设置为1的话，就是在训练的时候每一batch图片会随便改成320-640（32整倍数）大小的图片。
                            # # # 目的和上面的色度，曝光度等一样为了增强训练效果。如果设置为0的话，所有图片就只修改成默认的大小 416*416。
                            # # # （2018.04.08更新, 有朋友说这里如果设置为1的话，训练的时候obj和noobj会出现全为0的情况，设置为0后一切正常。）
                            # # # 这个文件的最下面有3个YOLO层，这里我才放上来了一个，这三个地方的classes做相应修改
                            # # # 每个YOLO层的上一层的convolutional层的filters也要修改


